### ðŸ‘‹ Hi there, I'm Daniel,

![avatar](https://images.weserv.nl/?url=avatars.githubusercontent.com/u/53251018?v=4&h=150&w=150&fit=cover&mask=circle&maxage=7d)

I'm a self-taught Data Scientist specialized in Artificial Intelligence (traditional Machine Learning and Deep Learning). Within the field of Machine Learning, I am primarily (but not exclusively) interested in these topics:
* Interpretable ML and XAI
* Computer Vision
* Reinforcement Learning

### ðŸ“¬Connect with Me
* [LinkedIn](https://www.linkedin.com/in/danielkleine5)
* [Medium](https://dkleine.medium.com/)


### Projects

#### [Machine Learning DevOs (MLOps)](https://github.com/d-kleine/Udacity_MLOps)
Optimized integration of Machine Learning models and deploy them in a production-level environment

**Project 1: Clean Code Principles**

*Deploying Machine Learning Models in Production:*
-	Using best practices for coding using PyLint and AutoPEP8
-	Improve Git and GitHub skills to work with teams
-	Testing and logging best practices used in production environments to ensure models stand the test of time

**Project 2: Building a Reproducible Model Workflow**

*Efficiency, effectiveness, and productivity in modern, real ML projects best practices around reproducible ML workflows:*
-	Build a clean, organized, reproducible end-to-end machine learning pipeline with MLflow from scratch 
-	Clean and validate the data with pytest 
-	Track experiments, code, and results using GitHub and Weights & Biases
-	Selection of the most powerful model for production
-	Deploy a model using MLflow

**Project 3: Deploying a Scalable ML Pipeline in Production**

*Use of a machine learning model in production:* 
-	Model performance, check for bias using slices of data and write a model map
-	Version control of data and models with Data Version Control (DVC) 
-	Perform Continuous Integration (CI) with GitHub Actions and Continuous Delivery/Deployment (CD)
-	Write a user interface (API) with FastAPI fast, type checked and auto-documented

**Project 4: Automated model scoring and monitoring**

*Full automation of MLOps processes required to evaluate and redeploy ML models:*
-	Automation of model training and deployment
-	Establishment of regular evaluation processes: Re-training and re-deployment of models at model drift
-	Diagnose operational issues with models, including data integrity and stability issues, timing issues, and dependency issues
-	Set up automated reports for APIs
